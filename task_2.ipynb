{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60289166-cb16-41e6-a550-7dd9666c7b9a",
   "metadata": {},
   "source": [
    "## Task 2. Neural Network Models for Combined Classification and Regression\n",
    "In this task, we aim to develop and evaluate neural network models capable of performing both classification and regression tasks simultaneously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60bbb18-a93e-40bf-b4d0-73d119717224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7afd5baa-358b-4d59-81bd-9a52549b3c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2.10.0-76-gfdfc646704c 2.10.1\n",
      "True\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "def enableGPU():\n",
    "    print(tf.version.GIT_VERSION, tf.version.VERSION)\n",
    "    print(tf.test.is_built_with_cuda())\n",
    "    #tf.debugging.set_log_device_placement(True)\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "      try:\n",
    "        for gpu in gpus:\n",
    "          # tf.config.experimental.set_memory_growth(gpu, True)\n",
    "          tf.config.set_logical_device_configuration(gpus[0],[tf.config.LogicalDeviceConfiguration(memory_limit=5024)])\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "      except RuntimeError as e:\n",
    "        print(e)\n",
    "enableGPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a97197-8308-4a7a-ab98-9f4d336e496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import subprocess as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import  layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, concatenate, Flatten, Conv2D, MaxPooling2D\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2e3024-ef26-4675-b7d8-517f58496e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b014970d-4cb0-4cb6-8769-3e3a198581d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"C:\\\\Users\\\\Tomi\\\\Desktop\\\\archive\\\\fruits-360_dataset\\\\fruits-360\\\\Training\"\n",
    "test_path = \"C:\\\\Users\\\\Tomi\\\\Desktop\\\\archive\\\\fruits-360_dataset\\\\fruits-360\\\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b27b7b8-dff3-4a60-9398-4e521ac77c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(Conv2D(filters=64, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu', input_shape=(100,100,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    model.add(Conv2D(filters=192, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dense(1)) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90ad9cc4-7ef6-4d16-a458-eccea0320ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67692 images belonging to 131 classes.\n",
      "Found 11335 images belonging to 131 classes.\n",
      "Found 11353 images belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define image size and batch size\n",
    "IMAGE_SIZE = (100, 100)  # Fruits 360 images are 100x100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Define paths to your dataset\n",
    "TRAIN_DATA_PATH = train_path\n",
    "VALIDATION_DATA_PATH = test_path\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.5)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_PATH,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_PATH,\n",
    "    # shuffle=True,\n",
    "    subset=\"validation\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_PATH,\n",
    "    # shuffle=True,\n",
    "    subset=\"training\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "NumClasses = train_generator.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed512ca4-a8ec-49e2-8786-6fe282a6095b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_58 (Conv2D)          (None, 23, 23, 64)        23296     \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 11, 11, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 11, 11, 192)       307392    \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 5, 5, 192)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 5, 5, 384)         663936    \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 5, 5, 256)         884992    \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 2, 2, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 4096)              4198400   \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,863,425\n",
      "Trainable params: 22,863,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "2116/2116 [==============================] - 434s 204ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 2/10\n",
      "2116/2116 [==============================] - 371s 175ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 3/10\n",
      "2116/2116 [==============================] - 359s 170ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 4/10\n",
      "2116/2116 [==============================] - 404s 191ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 5/10\n",
      "2116/2116 [==============================] - 337s 159ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 6/10\n",
      "2116/2116 [==============================] - 377s 178ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 7/10\n",
      "2116/2116 [==============================] - 336s 159ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 8/10\n",
      "2116/2116 [==============================] - 344s 163ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 9/10\n",
      "2116/2116 [==============================] - 388s 184ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 10/10\n",
      "2116/2116 [==============================] - 361s 171ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0077 - val_mae: 0.0077\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath='model_weights_epoch_REG{epoch:02d}.h5', save_weights_only=True, save_freq='epoch')\n",
    "model = create_model()\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mae', metrics=['mae'])\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, callbacks=[checkpoint_callback], verbose=1)\n",
    "model.save('REG_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f876f7d-210c-4cc2-bd31-f9370677a537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/355 [==============================] - 14s 40ms/step - loss: 0.0077 - mae: 0.0077\n",
      "evaluate mae: 0.77%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model_weights_epoch_REG10.h5')\n",
    "scores = model.evaluate(test_generator)\n",
    "print(\"%s%s: %.2f%%\" % (\"evaluate \",model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
